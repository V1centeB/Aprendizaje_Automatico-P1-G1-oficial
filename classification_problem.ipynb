{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendizaje Automático - Práctica 1\n",
    "Autores: RICARDO ANTONIO PAZOS VALERO - 100472303 / VICENTE ANTONIO BARBATO - 10043114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Problema de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera Parte: Usar modelo final para comprobar predicciones de valores altos y valores bajos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas - Energía alta:\n",
      "MAE: 363.7577378572341\n",
      "MSE: 239320.74546830868\n",
      "R^2: -0.4971161919850622\n",
      "\n",
      "Métricas - Energía baja:\n",
      "MAE: 170.5557617801548\n",
      "MSE: 63013.68075778485\n",
      "R^2: 0.36233044154224947\n"
     ]
    }
   ],
   "source": [
    "# Importamos\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Cargamos datos\n",
    "data = pd.read_csv('data/wind_ava.csv')\n",
    "\n",
    "# Cargamos el modelo final\n",
    "final_model = load('modelo_final.pkl')\n",
    "\n",
    "# Filtramos los datos para ver solo los datos metereológicos obtenidos para Sotavento \n",
    "data_filter = [columna for columna in data.columns if columna.endswith('.13') or columna == \"energy\"]\n",
    "data_sotavento = data[data_filter]\n",
    "data_sotavento = data_sotavento.copy()  # Hacemos una copia de los datos para evitar el SettingWithCopyWarning\n",
    "\n",
    "# Definimos el tercer cuantil\n",
    "energy_tq = data_sotavento['energy'].quantile(0.75)\n",
    "\n",
    "# Creamos una nueva variable target - la definimos como una variable binaria (más fácil de trabajar con variables binarias)\n",
    "# Clase alta = 1\n",
    "# Clase baja = 0\n",
    "data_sotavento['energy_level'] = (data_sotavento['energy'] > energy_tq).astype(int)\n",
    "\n",
    "# Hacemos las predicciones con el modelo final\n",
    "predictions = final_model.predict(data_sotavento.drop(columns=['energy', 'energy_level']))\n",
    "\n",
    "# Separamos los datos en dos subsets de energía alta o energía baja\n",
    "high_energy = data_sotavento[data_sotavento['energy_level'] == 1]\n",
    "low_energy = data_sotavento[data_sotavento['energy_level'] == 0]\n",
    "\n",
    "# Hacemos predicciones para cada subset por separado\n",
    "high_energy_predictions = predictions[high_energy.index]\n",
    "low_energy_predictions = predictions[low_energy.index]\n",
    "\n",
    "# Evaluamos el modelo en cada subset por separado\n",
    "high_energy_mae = mean_absolute_error(high_energy['energy'], high_energy_predictions)\n",
    "high_energy_mse = mean_squared_error(high_energy['energy'], high_energy_predictions)\n",
    "high_energy_r2 = r2_score(high_energy['energy'], high_energy_predictions)\n",
    "\n",
    "low_energy_mae = mean_absolute_error(low_energy['energy'], low_energy_predictions)\n",
    "low_energy_mse = mean_squared_error(low_energy['energy'], low_energy_predictions)\n",
    "low_energy_r2 = r2_score(low_energy['energy'], low_energy_predictions)\n",
    "\n",
    "# Comparamos métricas\n",
    "print(\"Métricas - Energía alta:\")\n",
    "print(\"MAE:\", high_energy_mae)\n",
    "print(\"MSE:\", high_energy_mse)\n",
    "print(\"R^2:\", high_energy_r2)\n",
    "\n",
    "print(\"\\nMétricas - Energía baja:\")\n",
    "print(\"MAE:\", low_energy_mae)\n",
    "print(\"MSE:\", low_energy_mse)\n",
    "print(\"R^2:\", low_energy_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que tenemos mejores resultados en las predicciones de los valores de energía baja en comparación con las predicciones de los valores de energía alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda Parte: Cambiar a un modelo de clasificación\n",
    "Para el problema de clasificación elegimos el DecisionTreeClassifier. Nos interesa utilizar su hiper-parámetro \"weight_class\" para poder lidiar con el desbalanceo de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'Decision Tree__criterion': 'entropy', 'Decision Tree__max_depth': 2, 'Decision Tree__min_samples_leaf': 1, 'Decision Tree__min_samples_split': 2}\n",
      "Accuracy: 0.8385449904275686\n",
      "Precision-Recall: 0.7080103359173127\n",
      "F1: 0.6841448189762797\n",
      "ROC AUC: 0.7946831340603512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importamos\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Para simplificar nuestro set de datos, ahora con la variable de energía \"alta\" = 1 o \"baja\" = 0, borramos la variable \"energy\"\n",
    "data_sotavento = data_sotavento.drop(columns=['energy'])\n",
    "\n",
    "# Definimos nuestro data (atributos meteorolócios) y nuestro target (clase de energía)\n",
    "X, y = data_sotavento.filter(regex=\".13\"), data_sotavento.energy_level\n",
    "\n",
    "# Hacemos un split de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=100472303)\n",
    "\n",
    "# Hacemos nuestro pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('Decision Tree', DecisionTreeClassifier(class_weight='balanced', random_state=100472303))\n",
    "])\n",
    "\n",
    "# Definimos los parámetros para la búsqueda en rejilla\n",
    "param_grid = {\n",
    "    'Decision Tree__criterion': ['gini', 'entropy'],\n",
    "    'Decision Tree__max_depth': [None, 2, 3, 4, 5, 6],\n",
    "    'Decision Tree__min_samples_split': [2, 5, 10],\n",
    "    'Decision Tree__min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Entrenamos el modelo\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Imprimimos los mejores parámetros\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "\n",
    "# Hacemos predicciones con el mejor modelo\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Calculamos métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Imprimimos resultados\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision-Recall: {precision_recall}\\nF1: {f1}\\nROC AUC: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusiones \n",
    "\n",
    "Inicialmente hemos decidido aplicar una búsqueda en rejilla para llevar a cabo la implementación del modelo haciendo uso de los hiperparámetros que mejor se adapten. Obteniendo como resultado:\n",
    "\n",
    "    -Criterion = Entropy\n",
    "    -Max_depth = 2\n",
    "    -Min_samples_leaf = 1\n",
    "    -Min_samples_split = 2\n",
    "\n",
    "Gracias a estos hiper parámetros, y a que hacemos uso del balanceo de pesos, el cuál se encarga de otorgar relevancia equitativa a clases con menor frecuencia de aparición que las que tienen una mayor frecuencia, nuestro modelo consigue acertar las predicciones de los datos de eneregía con un 83% de presición lo cual es una tasa elevada. Adicional a ello, acierta con una exactitud bastante aceptable a la hora de definir casos que realmente son positivos (Presicion-Recall) casi en un 71% de las  veces. Para finalizar destacamos que nuestro modelo presenta valores de F1 Score de 0.684 siendo valores bastante sólidos y indicando un buen equilibrio entre precisión y recall, y una elevada capacidad de discriminar entre las clases positivas y negativas, debido a que obtiene un valor bastante cercano al 1 (0,79 puntos) de ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Implementación ChatGpt \n",
    "\n",
    "A lo largo de la práctica nos hemos apoyado en la utilización de ChatGPT a la hora de necesitar contenido con mayor detalle o algún ejemplo de cómo hacer un uso correcto de la librería de scikit-learn. Además, nos ha servido para la verificación de sintaxis de nuestro código y en el relleno del mismo, debido a que son unas de las funciones que ofrece la extensión de Copilot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
