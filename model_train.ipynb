{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendizaje Automático - Práctica 1\n",
    "Autores: RICARDO ANTONIO PAZOS VALERO - 100472303 / VICENTE ANTONIO BARBATO - 10043114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Head ========================================================================\n",
      "\n",
      "              datetime   energy     p54.162.1     p54.162.2     p54.162.3  \\\n",
      "0  2005-01-02 18:00:00   402.71  2.534970e+06  2.526864e+06  2.518754e+06   \n",
      "1  2005-01-03 00:00:00   696.80  2.537369e+06  2.529277e+06  2.521184e+06   \n",
      "2  2005-01-03 06:00:00  1591.15  2.533727e+06  2.525703e+06  2.517678e+06   \n",
      "3  2005-01-03 12:00:00  1338.62  2.534491e+06  2.526548e+06  2.518609e+06   \n",
      "4  2005-01-03 18:00:00   562.50  2.529543e+06  2.521623e+06  2.513702e+06   \n",
      "\n",
      "      p54.162.4     p54.162.5     p54.162.6     p54.162.7     p54.162.8  ...  \\\n",
      "0  2.510648e+06  2.502537e+06  2.531111e+06  2.522721e+06  2.514330e+06  ...   \n",
      "1  2.513088e+06  2.504995e+06  2.533465e+06  2.525088e+06  2.516716e+06  ...   \n",
      "2  2.509654e+06  2.501629e+06  2.529801e+06  2.521496e+06  2.513187e+06  ...   \n",
      "3  2.510670e+06  2.502732e+06  2.530569e+06  2.522346e+06  2.514127e+06  ...   \n",
      "4  2.505782e+06  2.497861e+06  2.525621e+06  2.517421e+06  2.509215e+06  ...   \n",
      "\n",
      "    v100.16   v100.17   v100.18   v100.19   v100.20   v100.21   v100.22  \\\n",
      "0 -4.683596 -4.545396 -4.407196 -4.268996 -4.131295 -4.669626 -4.528932   \n",
      "1 -3.397886 -3.257192 -3.115998 -2.975304 -2.834609 -3.396390 -3.254198   \n",
      "2 -1.454105 -1.296447 -1.138290 -0.980134 -0.822476 -1.459094 -1.302933   \n",
      "3  1.255015  1.370265  1.485515  1.600765  1.716015  1.210612  1.319376   \n",
      "4  1.939031  2.023847  2.108663  2.193977  2.278793  1.873673  1.953000   \n",
      "\n",
      "    v100.23   v100.24   v100.25  \n",
      "0 -4.388736 -4.248540 -4.107846  \n",
      "1 -3.112506 -2.970314 -2.828622  \n",
      "2 -1.147271 -0.991110 -0.834949  \n",
      "3  1.428140  1.536405  1.645169  \n",
      "4  2.031829  2.111157  2.189986  \n",
      "\n",
      "[5 rows x 552 columns]\n",
      "=== Data Info ========================================================================\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4748 entries, 0 to 4747\n",
      "Columns: 552 entries, datetime to v100.25\n",
      "dtypes: float64(551), object(1)\n",
      "memory usage: 20.0+ MB\n",
      "None\n",
      "=== Data Description =================================================================\n",
      "\n",
      "            energy     p54.162.1     p54.162.2     p54.162.3     p54.162.4  \\\n",
      "count  4748.000000  4.748000e+03  4.748000e+03  4.748000e+03  4.748000e+03   \n",
      "mean    693.126247  2.512813e+06  2.505046e+06  2.497279e+06  2.489512e+06   \n",
      "std     665.531609  4.497381e+04  4.495651e+04  4.494192e+04  4.493019e+04   \n",
      "min       0.010000  2.380345e+06  2.373125e+06  2.365683e+06  2.358246e+06   \n",
      "25%     144.170000  2.481864e+06  2.474130e+06  2.466337e+06  2.458519e+06   \n",
      "50%     465.305000  2.513695e+06  2.506059e+06  2.498363e+06  2.490571e+06   \n",
      "75%    1089.375000  2.548630e+06  2.540981e+06  2.533183e+06  2.525478e+06   \n",
      "max    2792.550000  2.604194e+06  2.596310e+06  2.588421e+06  2.580532e+06   \n",
      "\n",
      "          p54.162.5     p54.162.6     p54.162.7     p54.162.8     p54.162.9  \\\n",
      "count  4.748000e+03  4.748000e+03  4.748000e+03  4.748000e+03  4.748000e+03   \n",
      "mean   2.481745e+06  2.509016e+06  2.500971e+06  2.492926e+06  2.484881e+06   \n",
      "std    4.492122e+04  4.490920e+04  4.489159e+04  4.487687e+04  4.486493e+04   \n",
      "min    2.350809e+06  2.376676e+06  2.369443e+06  2.361811e+06  2.354099e+06   \n",
      "25%    2.450773e+06  2.478125e+06  2.469988e+06  2.461939e+06  2.453929e+06   \n",
      "50%    2.482747e+06  2.509925e+06  2.502036e+06  2.493928e+06  2.485854e+06   \n",
      "75%    2.517725e+06  2.544740e+06  2.536842e+06  2.528673e+06  2.520778e+06   \n",
      "max    2.572648e+06  2.600268e+06  2.592103e+06  2.583939e+06  2.575774e+06   \n",
      "\n",
      "       ...      v100.16      v100.17      v100.18      v100.19      v100.20  \\\n",
      "count  ...  4748.000000  4748.000000  4748.000000  4748.000000  4748.000000   \n",
      "mean   ...     0.255938     0.292265     0.328594     0.364920     0.401249   \n",
      "std    ...     4.923671     4.778554     4.636230     4.496968     4.361058   \n",
      "min    ...   -13.737945   -13.359267   -12.980589   -12.601412   -12.222734   \n",
      "25%    ...    -3.560409    -3.397387    -3.237859    -3.077207    -2.934642   \n",
      "50%    ...    -0.506162    -0.460262    -0.377691    -0.305598    -0.244480   \n",
      "75%    ...     3.751223     3.666906     3.615393     3.539931     3.467963   \n",
      "max    ...    17.730758    17.229346    16.774832    16.366718    15.959103   \n",
      "\n",
      "           v100.21      v100.22      v100.23      v100.24      v100.25  \n",
      "count  4748.000000  4748.000000  4748.000000  4748.000000  4748.000000  \n",
      "mean      0.232342     0.269122     0.305908     0.342688     0.379472  \n",
      "std       4.866355     4.721771     4.579891     4.440984     4.305331  \n",
      "min     -13.712999   -13.326339   -12.939179   -12.552518   -12.165857  \n",
      "25%      -3.531347    -3.375186    -3.212040    -3.050266    -2.897098  \n",
      "50%      -0.504167    -0.459015    -0.383678    -0.324307    -0.254209  \n",
      "75%       3.695469     3.610528     3.554649     3.454866     3.406346  \n",
      "max      17.571603    17.080170    16.588237    16.096804    15.681705  \n",
      "\n",
      "[8 rows x 551 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importamos \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns (SI HACEMOS GRÁFICOS)\n",
    "\n",
    "# Cargamos datos - wind_ava.csv\n",
    "data = pd.read_csv('data/wind_ava.csv')\n",
    "\n",
    "# Comprobamos si se carga correctamente\n",
    "print(\"=== Data Head ========================================================================\\n\")\n",
    "print(data.head())\n",
    "\n",
    "# Observamos que hay hasta 4745 filas y 551 columnas.\n",
    "# Tipos encontrados: float64(551) and object(1)\n",
    "print(\"=== Data Info ========================================================================\\n\")\n",
    "print(data.info())\n",
    "\n",
    "# Observamos con un poco más detalle los datos con .describe()\n",
    "print(\"=== Data Description =================================================================\\n\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>energy</th>\n",
       "      <th>p54.162.13</th>\n",
       "      <th>p55.162.13</th>\n",
       "      <th>cape.13</th>\n",
       "      <th>p59.162.13</th>\n",
       "      <th>lai_lv.13</th>\n",
       "      <th>lai_hv.13</th>\n",
       "      <th>u10n.13</th>\n",
       "      <th>v10n.13</th>\n",
       "      <th>...</th>\n",
       "      <th>t2m.13</th>\n",
       "      <th>stl2.13</th>\n",
       "      <th>stl3.13</th>\n",
       "      <th>iews.13</th>\n",
       "      <th>inss.13</th>\n",
       "      <th>stl4.13</th>\n",
       "      <th>fsr.13</th>\n",
       "      <th>flsr.13</th>\n",
       "      <th>u100.13</th>\n",
       "      <th>v100.13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-02 18:00:00</td>\n",
       "      <td>402.71</td>\n",
       "      <td>2.510824e+06</td>\n",
       "      <td>9.186295</td>\n",
       "      <td>13.527577</td>\n",
       "      <td>1.386937e+06</td>\n",
       "      <td>2.344111</td>\n",
       "      <td>2.432983</td>\n",
       "      <td>-0.757587</td>\n",
       "      <td>-1.922799</td>\n",
       "      <td>...</td>\n",
       "      <td>280.473098</td>\n",
       "      <td>281.042026</td>\n",
       "      <td>281.462478</td>\n",
       "      <td>-0.057958</td>\n",
       "      <td>-0.138650</td>\n",
       "      <td>284.684755</td>\n",
       "      <td>0.404731</td>\n",
       "      <td>-5.927092</td>\n",
       "      <td>-1.780562</td>\n",
       "      <td>-4.443617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-03 00:00:00</td>\n",
       "      <td>696.80</td>\n",
       "      <td>2.513173e+06</td>\n",
       "      <td>8.849569</td>\n",
       "      <td>6.896412</td>\n",
       "      <td>1.153526e+06</td>\n",
       "      <td>2.343719</td>\n",
       "      <td>2.432838</td>\n",
       "      <td>-1.412620</td>\n",
       "      <td>-1.403011</td>\n",
       "      <td>...</td>\n",
       "      <td>278.286616</td>\n",
       "      <td>280.747406</td>\n",
       "      <td>281.486541</td>\n",
       "      <td>-0.103576</td>\n",
       "      <td>-0.083050</td>\n",
       "      <td>284.667948</td>\n",
       "      <td>0.404920</td>\n",
       "      <td>-5.913881</td>\n",
       "      <td>-3.743344</td>\n",
       "      <td>-3.129469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-03 06:00:00</td>\n",
       "      <td>1591.15</td>\n",
       "      <td>2.509627e+06</td>\n",
       "      <td>7.924080</td>\n",
       "      <td>4.774439</td>\n",
       "      <td>1.098754e+06</td>\n",
       "      <td>2.343300</td>\n",
       "      <td>2.432704</td>\n",
       "      <td>-2.290185</td>\n",
       "      <td>-0.754580</td>\n",
       "      <td>...</td>\n",
       "      <td>277.206490</td>\n",
       "      <td>280.114863</td>\n",
       "      <td>281.487095</td>\n",
       "      <td>-0.165721</td>\n",
       "      <td>-0.036241</td>\n",
       "      <td>284.651914</td>\n",
       "      <td>0.405704</td>\n",
       "      <td>-5.908272</td>\n",
       "      <td>-5.097203</td>\n",
       "      <td>-1.157748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-03 12:00:00</td>\n",
       "      <td>1338.62</td>\n",
       "      <td>2.510571e+06</td>\n",
       "      <td>6.922709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.076021e+06</td>\n",
       "      <td>2.342830</td>\n",
       "      <td>2.432514</td>\n",
       "      <td>-3.497855</td>\n",
       "      <td>1.271028</td>\n",
       "      <td>...</td>\n",
       "      <td>280.926600</td>\n",
       "      <td>279.991138</td>\n",
       "      <td>281.472435</td>\n",
       "      <td>-0.275550</td>\n",
       "      <td>0.098192</td>\n",
       "      <td>284.636266</td>\n",
       "      <td>0.403967</td>\n",
       "      <td>-5.961995</td>\n",
       "      <td>-4.500835</td>\n",
       "      <td>1.502478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-03 18:00:00</td>\n",
       "      <td>562.50</td>\n",
       "      <td>2.505664e+06</td>\n",
       "      <td>6.646282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.070830e+06</td>\n",
       "      <td>2.342437</td>\n",
       "      <td>2.432369</td>\n",
       "      <td>-0.971249</td>\n",
       "      <td>0.553060</td>\n",
       "      <td>...</td>\n",
       "      <td>277.363875</td>\n",
       "      <td>280.576898</td>\n",
       "      <td>281.473265</td>\n",
       "      <td>-0.056553</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>284.620232</td>\n",
       "      <td>0.403808</td>\n",
       "      <td>-5.987860</td>\n",
       "      <td>-3.392324</td>\n",
       "      <td>2.131114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime   energy    p54.162.13  p55.162.13    cape.13  \\\n",
       "0  2005-01-02 18:00:00   402.71  2.510824e+06    9.186295  13.527577   \n",
       "1  2005-01-03 00:00:00   696.80  2.513173e+06    8.849569   6.896412   \n",
       "2  2005-01-03 06:00:00  1591.15  2.509627e+06    7.924080   4.774439   \n",
       "3  2005-01-03 12:00:00  1338.62  2.510571e+06    6.922709   0.000000   \n",
       "4  2005-01-03 18:00:00   562.50  2.505664e+06    6.646282   0.000000   \n",
       "\n",
       "     p59.162.13  lai_lv.13  lai_hv.13   u10n.13   v10n.13  ...      t2m.13  \\\n",
       "0  1.386937e+06   2.344111   2.432983 -0.757587 -1.922799  ...  280.473098   \n",
       "1  1.153526e+06   2.343719   2.432838 -1.412620 -1.403011  ...  278.286616   \n",
       "2  1.098754e+06   2.343300   2.432704 -2.290185 -0.754580  ...  277.206490   \n",
       "3  1.076021e+06   2.342830   2.432514 -3.497855  1.271028  ...  280.926600   \n",
       "4  1.070830e+06   2.342437   2.432369 -0.971249  0.553060  ...  277.363875   \n",
       "\n",
       "      stl2.13     stl3.13   iews.13   inss.13     stl4.13    fsr.13   flsr.13  \\\n",
       "0  281.042026  281.462478 -0.057958 -0.138650  284.684755  0.404731 -5.927092   \n",
       "1  280.747406  281.486541 -0.103576 -0.083050  284.667948  0.404920 -5.913881   \n",
       "2  280.114863  281.487095 -0.165721 -0.036241  284.651914  0.405704 -5.908272   \n",
       "3  279.991138  281.472435 -0.275550  0.098192  284.636266  0.403967 -5.961995   \n",
       "4  280.576898  281.473265 -0.056553  0.041844  284.620232  0.403808 -5.987860   \n",
       "\n",
       "    u100.13   v100.13  \n",
       "0 -1.780562 -4.443617  \n",
       "1 -3.743344 -3.129469  \n",
       "2 -5.097203 -1.157748  \n",
       "3 -4.500835  1.502478  \n",
       "4 -3.392324  2.131114  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime       object\n",
       "energy        float64\n",
       "p54.162.13    float64\n",
       "p55.162.13    float64\n",
       "cape.13       float64\n",
       "p59.162.13    float64\n",
       "lai_lv.13     float64\n",
       "lai_hv.13     float64\n",
       "u10n.13       float64\n",
       "v10n.13       float64\n",
       "sp.13         float64\n",
       "stl1.13       float64\n",
       "u10.13        float64\n",
       "v10.13        float64\n",
       "t2m.13        float64\n",
       "stl2.13       float64\n",
       "stl3.13       float64\n",
       "iews.13       float64\n",
       "inss.13       float64\n",
       "stl4.13       float64\n",
       "fsr.13        float64\n",
       "flsr.13       float64\n",
       "u100.13       float64\n",
       "v100.13       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtramos los datos para ver solo los datos metereológicos obtenidos para Sotavento\n",
    "data_sotavento = [columna for columna in data.columns if columna.endswith('.13') or columna == \"datetime\" or columna == \"energy\"]\n",
    "data_filter = data[data_sotavento]\n",
    "\n",
    "# Visualizamos los datos resultantes\n",
    "data_filter.head()\n",
    "display(data_filter.head())\n",
    "# Observamos que reducimos el número de columnas a 24\n",
    "\n",
    "# Buscamos por valores nulos\n",
    "null_values = data_filter.isna().any()\n",
    "null_values\n",
    "# Observamos que no hay valores nulos\n",
    "\n",
    "# Buscamos por valores duplicados\n",
    "data_filter.duplicated().sum()\n",
    "# Observamos que no hay valores duplicados\n",
    "\n",
    "# Hacemos un análisis de los tipos de datos restantes\n",
    "data_filter.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluación inner y outer. Métricas\n",
    "Para la evaluación outer haremos un simple train-test split del conjunto de datos. Partimos el conjunto en 1/3 para test y 2/3 para train.\n",
    "Para la evaluación inner haremos un split del conjunto train en otro conjunto train y un conjunto de validación para realizar el HPO. Recordamos que nuestro conjunto de datos tiene una secuencia temporal, por lo que no sería sabio proceder con una Validación Cruzada KFold, ya que nos mezclará los datos y no debemos validar un entrenamiento de datos nuevos con datos viejos. Debemos entrenar con los datos viejos y validar con los datos nuevos. Por tanto, optamos por un Time Series Split. Haremos un total de 5 evaluaciones distintas con el Time Series Split.\n",
    "Para la métrica a usar, escogemos MAE (Mean Absolute Error) para la búsqueda del método de escalado debido a su robustez ante outliers. Más adelante, utilizaremos MSE y R^2 también para tener un poco más de información sobre los errores medios obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Método de Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN con StandarScaler': 322.19241998734975,\n",
       " 'KNN con MinMaxScaler': 338.41487666034163,\n",
       " 'KNN con RobustScaler': 334.3120518659076}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importamos lo necesario para comenzar\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Definimos nuestro data (atributos meteorolócios) y nuestro target (energía producida)\n",
    "X, y = data_filter.filter(regex=\".13\"), data_filter.energy\n",
    "\n",
    "# Hacemos el split train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=100472303)\n",
    "\n",
    "# Hacemos el split train-train train-validate\n",
    "X_train_train, X_train_validate, y_train_train, y_train_validate = train_test_split(X_train, y_train, test_size=1/3, random_state=100472303)\n",
    "\n",
    "# Comenzamos evaluación inner\n",
    "inner = TimeSeriesSplit(n_splits=3)\n",
    "inner_scores = {}\n",
    "\n",
    "# Evaluamos KNNRegressor con StandarScaler\n",
    "pipeline_std = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "scores_std = cross_val_score(pipeline_std, X_train_train, y_train_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "inner_scores['KNN con StandarScaler'] = -scores_std.mean()\n",
    "\n",
    "# Evaluamos KNNRegressor con MinMaxScaler\n",
    "pipeline_std = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "scores_minmax = cross_val_score(pipeline_std, X_train_train, y_train_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "inner_scores['KNN con MinMaxScaler'] = -scores_minmax.mean()\n",
    "\n",
    "# Evaluamos KNNRegressor con Robustscaler\n",
    "pipeline_std = Pipeline([\n",
    "    ('scaler', RobustScaler()), \n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "scores_robust = cross_val_score(pipeline_std, X_train_train, y_train_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "inner_scores['KNN con RobustScaler'] = -scores_robust.mean()\n",
    "\n",
    "# Observamos resultados\n",
    "display(inner_scores)\n",
    "# Vemos que el error mínimo aparece al usar StandardScaler, por lo que continuamos con el StandardScaler\n",
    "\n",
    "# Transformamos data para escalarla con nuestro método de escalado elegido\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Escalamos los datos para el desarrollo \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=1/3, random_state=100472303)\n",
    "X_train_train, X_train_validate, y_train_train, y_train_validate = train_test_split(X_train, y_train, test_size=1/3, random_state=100472303)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Elección de Modelo\n",
    "KNN, árboles de regresión, regresión lineal (la normal y, al menos, la variante Lasso) y SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado A: Evaluación de modelos con hiperparámetros omitidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNN Regressor\n",
      "  MAE: 309.3994293838863\n",
      "  MSE: 173449.2870951166\n",
      "  R^2: 0.5968498164568965\n",
      "  Training Time: 0.0009832382202148438\n",
      "  Prediction Time: 0.009761810302734375\n",
      "\n",
      "Model: Regressor Tree\n",
      "  MAE: 384.8008530805687\n",
      "  MSE: 282550.19440246443\n",
      "  R^2: 0.34326531609768607\n",
      "  Training Time: 0.06835532188415527\n",
      "  Prediction Time: 0.0\n",
      "\n",
      "Model: Linear Regression\n",
      "  MAE: 432.3896902952508\n",
      "  MSE: 302411.605914322\n",
      "  R^2: 0.2971012076684624\n",
      "  Training Time: 0.003908872604370117\n",
      "  Prediction Time: 0.0009768009185791016\n",
      "\n",
      "Model: Lasso Regression\n",
      "  MAE: 435.88637571727816\n",
      "  MSE: 306037.63711565273\n",
      "  R^2: 0.288673181420376\n",
      "  Training Time: 0.03124523162841797\n",
      "  Prediction Time: 0.0\n",
      "\n",
      "Model: SVR\n",
      "  MAE: 484.29266197443224\n",
      "  MSE: 425004.63614301995\n",
      "  R^2: 0.01215680999733304\n",
      "  Training Time: 0.16307330131530762\n",
      "  Prediction Time: 0.19336175918579102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importamos los modelos\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Importamos métricas\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Importamos time para medir el tiempo que toman los modelos\n",
    "import time\n",
    "\n",
    "# Definimos un diccionario para guardar los resultados\n",
    "results = {}\n",
    "\n",
    "# Definimos nuestros modelos\n",
    "models = {\n",
    "    \"KNN Regressor\": KNeighborsRegressor(),\n",
    "    \"Regressor Tree\": DecisionTreeRegressor(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "# Entrenamos y evaluamos los modelos\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()  # Empezamos el tiempo de entrenamiento\n",
    "    model.fit(X_train_train, y_train_train)\n",
    "    train_time = time.time() - start_time  # Tiempo de entrenamiento\n",
    "    start_time = time.time()  # Empezamos el tiempo para la predicción\n",
    "    y_pred = model.predict(X_train_validate)\n",
    "    prediction_time = time.time() - start_time  # Tiempo de predicción\n",
    "    mse = mean_squared_error(y_train_validate, y_pred)\n",
    "    mae = mean_absolute_error(y_train_validate, y_pred)\n",
    "    r2 = r2_score(y_train_validate, y_pred)\n",
    "    results[name] = {\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"R^2\": r2,\n",
    "        \"Training Time\": train_time,\n",
    "        \"Prediction Time\": prediction_time\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for name, result in results.items():\n",
    "    print(f\"Model: {name}\\n  MAE: {result['MAE']}\\n  MSE: {result['MSE']}\\n  R^2: {result['R^2']}\\n  Training Time: {result['Training Time']}\\n  Prediction Time: {result['Prediction Time']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado B: HPO\n",
    "Hacemos lo mismo, pero ahora cambiando los valores de los hiperparámetros más relevantes para ver si podemos conseguir un mejor resultado. Para ello, realizamos una búsqueda en rejilla para cada distinto modelo, probando distintos valores para los hiperparámetros, y comparamos al final los mejores resultados obtenidos. Además, definimos un dummy regressor para compara nuestros resultados.\n",
    "A continuación observamos los mejores valores para los hiperparámetros en nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.507e+07, tolerance: 2.179e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.856e+07, tolerance: 4.662e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.004e+07, tolerance: 7.022e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+05, tolerance: 2.179e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.543e+05, tolerance: 2.179e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.064e+05, tolerance: 4.662e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+05, tolerance: 7.022e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.620e+07, tolerance: 9.333e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNN Regressor\n",
      "  Best Parameters: {'n_neighbors': 9}\n",
      "  MAE: 308.8016240126383\n",
      "  MSE: 169132.0138963899\n",
      "  R^2: 0.6068845044721773\n",
      "  Training Time: 0.16892480850219727\n",
      "  Prediction Time: 0.006838083267211914\n",
      "\n",
      "Model: Regressor Tree\n",
      "  Best Parameters: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "  MAE: 328.91457240195444\n",
      "  MSE: 191770.82255165084\n",
      "  R^2: 0.5542648597482378\n",
      "  Training Time: 2.0242955684661865\n",
      "  Prediction Time: 0.0\n",
      "\n",
      "Model: Lasso Regression\n",
      "  Best Parameters: {'alpha': 0.1, 'max_iter': 1000}\n",
      "  MAE: 433.0187887837684\n",
      "  MSE: 302917.1287661191\n",
      "  R^2: 0.29592621505880434\n",
      "  Training Time: 1.3638362884521484\n",
      "  Prediction Time: 0.0009756088256835938\n",
      "\n",
      "Model: SVR\n",
      "  Best Parameters: {'C': 10.0, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "  MAE: 367.506343912799\n",
      "  MSE: 248202.6125926521\n",
      "  R^2: 0.4230997976501759\n",
      "  Training Time: 2.7791426181793213\n",
      "  Prediction Time: 0.1952800750732422\n",
      "\n",
      "Dummy Regressor (mean):\n",
      "  MAE: 540.1980079782574\n",
      "  MSE: 430273.4825400329\n",
      "  R^2: -8.963060551225865e-05\n",
      "\n",
      "Dummy Regressor (median):\n",
      "  MAE: 516.9479004739337\n",
      "  MSE: 479889.32258575835\n",
      "  R^2: -0.11541230131853952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importamos lo necesario para hacer un grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Importamos lo necesario para hacer un regresor dummy\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Definimos los distintos hiperparámetros que queremos probar\n",
    "param_grid_knn = {'n_neighbors': [3, 5, 7, 9]}\n",
    "param_grid_tree = {'max_depth': [None, 5, 10, 15],\n",
    "                   'min_samples_split': [2, 5, 10],\n",
    "                   'min_samples_leaf': [1, 2, 4]}\n",
    "param_grid_lasso = {'alpha': [0.1, 1.0, 10.0],\n",
    "                    'max_iter': [1000, 5000, 10000]}\n",
    "param_grid_svr = {'C': [0.1, 1.0, 10.0],\n",
    "                  'kernel': ['linear', 'rbf'],\n",
    "                  'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Definimos las distintas estrategias para el dummy regressor\n",
    "d_strats = ['mean', 'median']\n",
    "\n",
    "# Hacemos el grid search con nuestro Time Series Split y con una métrica MAE\n",
    "grid_searches = {\n",
    "    \"KNN Regressor\": GridSearchCV(KNeighborsRegressor(), param_grid_knn, scoring='neg_mean_absolute_error', cv=inner),\n",
    "    \"Regressor Tree\": GridSearchCV(DecisionTreeRegressor(), param_grid_tree, scoring='neg_mean_absolute_error', cv=inner),\n",
    "    \"Lasso Regression\": GridSearchCV(Lasso(), param_grid_lasso, scoring='neg_mean_absolute_error', cv=inner),\n",
    "    \"SVR\": GridSearchCV(SVR(), param_grid_svr, scoring='neg_mean_absolute_error', cv=inner)\n",
    "}\n",
    "\n",
    "# Evaluamos los mejores modelos del grid_search para sacar los tiempos\n",
    "results_grid_search = {}\n",
    "\n",
    "for name, grid_search in grid_searches.items():\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train_train, y_train_train)\n",
    "    train_time = time.time() - start_time\n",
    "    y_pred = grid_search.best_estimator_.predict(X_train_validate)\n",
    "    prediction_time = time.time() - start_time - train_time\n",
    "    mse = mean_squared_error(y_train_validate, y_pred)\n",
    "    mae = mean_absolute_error(y_train_validate, y_pred)\n",
    "    r2 = r2_score(y_train_validate, y_pred)\n",
    "    best_params = grid_search.best_params_\n",
    "    results_grid_search[name] = {\n",
    "        \"Best Parameters\": best_params,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"R^2\": r2,\n",
    "        \"Training Time\": train_time,\n",
    "        \"Prediction Time\": prediction_time\n",
    "    }\n",
    "\n",
    "# Evaluamos al dummy regressor con las distintas estrategias\n",
    "d_results = {}\n",
    "\n",
    "for strategy in d_strats:\n",
    "    dummy_regressor = DummyRegressor(strategy=strategy)\n",
    "    dummy_regressor.fit(X_train_train, y_train_train)\n",
    "    y_pred_dummy = dummy_regressor.predict(X_train_validate)\n",
    "    mse_dummy = mean_squared_error(y_train_validate, y_pred_dummy)\n",
    "    mae_dummy = mean_absolute_error(y_train_validate, y_pred_dummy)\n",
    "    r2_dummy = r2_score(y_train_validate, y_pred_dummy)\n",
    "    d_results[strategy] = {\n",
    "        \"MAE\": mae_dummy,\n",
    "        \"MSE\": mse_dummy,\n",
    "        \"R^2\": r2_dummy\n",
    "    }\n",
    "\n",
    "# Imprimimos los mejores resultados\n",
    "for name, result in results_grid_search.items():\n",
    "    print(f\"Model: {name}\\n  Best Parameters: {result['Best Parameters']}\\n  MAE: {result['MAE']}\\n  MSE: {result['MSE']}\\n  R^2: {result['R^2']}\\n  Training Time: {result['Training Time']}\\n  Prediction Time: {result['Prediction Time']}\\n\")\n",
    "\n",
    "# Imprimimos los resultados del dummy regressor\n",
    "for strategy, result in d_results.items():\n",
    "    print(f\"Dummy Regressor ({strategy}):\\n  MAE: {result['MAE']}\\n  MSE: {result['MSE']}\\n  R^2: {result['R^2']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado C: Conclusiones\n",
    "Observamos que el mejor método en cuanto a los errores es el KNN Regressor. También es el que tiene mejor tiempo de entrenamiento. Observamos que al ajustar los hiper-parámetros, los tiempos y los errores han mejorado. En algunos casos han mejorado bastante, y en otros, no tanto. Para el KNN Regressor observamos unas diferencias pequeñas entre los errores mientras que para el SVR observamos una diferencia más significativa. También observamos que con el ajuste de hiper-parámetros el tiempo de entrenamiento se vuelve aún mayor. Los tiempos de predicción muestran poca mejora o empeoramiento dependiendo del modelo. Por tanto, podemos decir que el tiempo de ejecución es inverso a la media de errores, por lo que podemos concluir que con un modelo más ajustado, que predice con mayor precisión, tomará más tiempo en el entrenamiento. También podemos observar que todos los modelos han superado al dummy regressor (en ambas estrategias). PENSAR EN CÓMO SACAR LOS HIPERPARÁMETROS MÁS RELEVANTES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluación modelo seleccionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado A: Selección mejor modelo\n",
    "\n",
    "Podemos observar basándonos en el análisis de los diversos modelos de regresión, y estudiar los resultados arojados por cada estimador para distintas métricas aplicadas en el apartado 4.b. Se evidencia que el modelo regresor KNN es el más óptimo para trabajar con del dataset proporcionado, debido a que nos está ofreciendo resultados mas precisos y eficientes que el resto de estimadores y en un tiempo de entrenamiento y de predicción bastante aceptable en comparación a los demás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado B: Evaluación outer con mejor modelo\n",
    "\n",
    "Para la validación externa del modelo seleccionado, haremos uso de una validación cruzada anidada, debido a que no tenemos un conjunto de datos reservados únicamente para dicha validación y le hemos proporcionado todo el dataset a nuestro modelo. De esta forma evitamos que nuestros resultados se vean afectados por un sobreajuste o que nuestra evaluación se vea sesgada por el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE promedio en validación cruzada externa (TimeSeriesSplit): 287.656802274163, Desviación estándar:\n"
     ]
    }
   ],
   "source": [
    "from statistics import stdev\n",
    "\n",
    "outer = TimeSeriesSplit(n_splits=3)\n",
    "   \n",
    "# Definición y ajuste del modelo en la validación cruzada interna\n",
    "model = grid_searches[\"KNN Regressor\"]\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba de la validación cruzada externa\n",
    "y_pred = model.predict(X_test)\n",
    "mean_score = mean_absolute_error(y_test, y_pred)\n",
    "# std_score = stdev(y_test, y_pred)\n",
    "\n",
    "print(f'MAE promedio en validación cruzada externa (TimeSeriesSplit): {mean_score}, Desviación estándar:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado C: Entrenamiento modelo final\n",
    "Para el modelo final agarramos todo el conjunto de datos y evaluamos nuestro modelo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_final.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos joblib para guardar nuestro modelo final\n",
    "from joblib import dump\n",
    "\n",
    "# Fit del modelo final\n",
    "model.fit(X, y)\n",
    "\n",
    "# Guardar el modelo final\n",
    "dump(model, 'modelo_final.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
